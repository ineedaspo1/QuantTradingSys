{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day by day trading - 2019-01-24 and on and on\n",
    "In theory, running this page over and over will continue to increment trades day by day.\n",
    "The only hiccup will probably be a holiday during business days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pylab as plt\n",
    "from pandas.tseries.offsets import BDay\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, TimeSeriesSplit\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import custom libraries\n",
    "from Code.lib.plot_utils import PlotUtility\n",
    "from Code.lib.time_utils import TimeUtility\n",
    "from Code.lib.retrieve_data import DataRetrieve, ComputeTarget\n",
    "from Code.lib.candle_indicators import CandleIndicators\n",
    "from Code.lib.transformers import Transformers\n",
    "from Code.lib.ta_momentum_studies import TALibMomentumStudies\n",
    "from Code.lib.model_utils import ModelUtility, TimeSeriesSplitImproved\n",
    "from Code.lib.feature_generator import FeatureGenerator\n",
    "from Code.utilities.stat_tests import stationarity_tests\n",
    "from Code.lib.config import current_feature, feature_dict\n",
    "from Code.models import models_utils\n",
    "from Code.lib.model_algos import AlgoUtility\n",
    "\n",
    "plotIt = PlotUtility()\n",
    "timeUtil = TimeUtility()\n",
    "ct = ComputeTarget()\n",
    "candle_ind = CandleIndicators()\n",
    "dSet = DataRetrieve()\n",
    "taLibMomSt = TALibMomentumStudies()\n",
    "transf = Transformers()\n",
    "modelUtil = ModelUtility()\n",
    "featureGen = FeatureGenerator()\n",
    "dSet = DataRetrieve()\n",
    "modelAlgo = AlgoUtility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create system directory based on system name if one doesn't already exist\n",
    "def get_system_dir(system_name):\n",
    "    # Create system directory in current path\n",
    "    current_directory = os.getcwd()\n",
    "    system_directory = os.path.join(current_directory, system_name)\n",
    "    if not os.path.exists(system_directory):\n",
    "       os.makedirs(system_directory)\n",
    "    return system_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions for save and load json files\n",
    "def save_json(filename, json_file):\n",
    "    # Save system_dict to file\n",
    "    #filename = 'system_dict.json'\n",
    "    file_path = os.path.join(system_directory, filename)\n",
    "    with open(file_path, 'w') as fp:\n",
    "        json.dump(json_file, fp, sort_keys=True, indent=4)\n",
    "        \n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as fp:\n",
    "        json_file = json.load(fp)\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "system_name = \"TLT-Long-system-7045-V1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get system info\n",
    "current_directory = os.getcwd()\n",
    "system_directory = os.path.join(current_directory, system_name)\n",
    "if not os.path.exists(system_directory):\n",
    "    print(\"system doesn't exist\")\n",
    "else:\n",
    "    filename = 'system_dict.json'    \n",
    "    file_path = os.path.join(system_directory, filename)\n",
    "    system_dict = load_json(file_path)\n",
    "    issue = system_dict[\"issue\"]\n",
    "    direction = system_dict[\"direction\"]\n",
    "    ver_num = system_dict[\"ver_num\"]\n",
    "    # Perhaps only load these when needed?\n",
    "    pivotDate = system_dict[\"pivot_date\"]\n",
    "    is_oos_ratio = system_dict[\"is_oos_ratio\"]\n",
    "    oos_months = system_dict[\"oos_months\"]\n",
    "    segments = system_dict[\"segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-14 00:00:00\n",
      "                    Segments:  1\n",
      "                IS OOS Ratio:  4\n",
      "                  OOS months:  4\n",
      "                   IS Months:  16\n",
      "              Months to load:  20\n",
      "              Data Load Date:  2017-05-14\n",
      "              IS Start  Date:  2017-06-14\n",
      "              OOS Start Date:  2018-10-14\n",
      "                  Pivot Date:  2019-02-14\n"
     ]
    }
   ],
   "source": [
    "# Set IS-OOS parameters\n",
    "from datetime import datetime\n",
    "pivotDate = datetime.strptime(pivotDate, '%Y-%m-%d')\n",
    "print(pivotDate)\n",
    "pivotDate = datetime.date(pivotDate)\n",
    "\n",
    "# set date splits\n",
    "isOosDates = timeUtil.is_oos_data_split(issue, pivotDate, is_oos_ratio, oos_months, segments)\n",
    "dataLoadStartDate = isOosDates[0]\n",
    "is_start_date = isOosDates[1]\n",
    "oos_start_date = isOosDates[2]\n",
    "is_months = isOosDates[3]\n",
    "is_end_date = isOosDates[4]\n",
    "oos_end_date = isOosDates[5]\n",
    "\n",
    "modelStartDate = oos_start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set trade date\n",
    "In this case, increment to next business day after pivotDate\n",
    "\n",
    "Do it manually for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "tradeDate = pivotDate + BDay(1)\n",
    "print(tradeDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'feature_dict.json'\n",
    "file_path = os.path.join(system_directory, file_name)\n",
    "feature_dict = load_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day by day procedure\n",
    "1. Set trade date\n",
    "2. Update close, transform\n",
    "3. Retrieve model\n",
    "4. Make prediction\n",
    "5. Update prev day gainAhead, trade (using TRADE DECISION), Equity (what df?)\n",
    "6. Update shadow trades df from (5)\n",
    "7. Calculate safe-f, CAR25 (TMS-Part 1)\n",
    "8. TRADE DECISION\n",
    "9. Update pivot date in dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to walkthrough\n",
    "1. Make copy of raw data and truncate it to pretend existing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved data series for TLT\n"
     ]
    }
   ],
   "source": [
    "raw_df = dSet.read_issue_data(issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>AdjClose</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>120.99</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>119.9700</td>\n",
       "      <td>120.0200</td>\n",
       "      <td>119.7479</td>\n",
       "      <td>11700412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>121.26</td>\n",
       "      <td>121.3800</td>\n",
       "      <td>119.9800</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>119.7679</td>\n",
       "      <td>12146772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>120.40</td>\n",
       "      <td>121.0500</td>\n",
       "      <td>120.2900</td>\n",
       "      <td>121.0500</td>\n",
       "      <td>120.7756</td>\n",
       "      <td>9879116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>120.65</td>\n",
       "      <td>121.5600</td>\n",
       "      <td>120.4600</td>\n",
       "      <td>121.5100</td>\n",
       "      <td>121.2345</td>\n",
       "      <td>17408971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>121.66</td>\n",
       "      <td>122.1600</td>\n",
       "      <td>121.3401</td>\n",
       "      <td>122.1500</td>\n",
       "      <td>121.8731</td>\n",
       "      <td>19841527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>122.29</td>\n",
       "      <td>123.8600</td>\n",
       "      <td>122.2267</td>\n",
       "      <td>123.5400</td>\n",
       "      <td>123.2599</td>\n",
       "      <td>21187045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>122.34</td>\n",
       "      <td>122.5600</td>\n",
       "      <td>121.6500</td>\n",
       "      <td>122.1100</td>\n",
       "      <td>121.8332</td>\n",
       "      <td>12970226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>122.62</td>\n",
       "      <td>122.6500</td>\n",
       "      <td>121.6200</td>\n",
       "      <td>121.7500</td>\n",
       "      <td>121.4740</td>\n",
       "      <td>8498104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>121.69</td>\n",
       "      <td>121.9400</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>121.4300</td>\n",
       "      <td>121.1547</td>\n",
       "      <td>7737103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>121.26</td>\n",
       "      <td>121.4300</td>\n",
       "      <td>120.7950</td>\n",
       "      <td>121.2400</td>\n",
       "      <td>120.9651</td>\n",
       "      <td>9349245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>121.28</td>\n",
       "      <td>121.4100</td>\n",
       "      <td>120.3400</td>\n",
       "      <td>120.4600</td>\n",
       "      <td>120.1869</td>\n",
       "      <td>8222860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>120.83</td>\n",
       "      <td>121.2700</td>\n",
       "      <td>120.6800</td>\n",
       "      <td>120.9300</td>\n",
       "      <td>120.6558</td>\n",
       "      <td>5786934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>120.90</td>\n",
       "      <td>121.0100</td>\n",
       "      <td>120.2416</td>\n",
       "      <td>120.4800</td>\n",
       "      <td>120.2069</td>\n",
       "      <td>6730681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>120.56</td>\n",
       "      <td>120.5700</td>\n",
       "      <td>119.9500</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>119.7679</td>\n",
       "      <td>8997352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>119.59</td>\n",
       "      <td>120.3900</td>\n",
       "      <td>119.5100</td>\n",
       "      <td>120.1600</td>\n",
       "      <td>119.8876</td>\n",
       "      <td>6048446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>120.22</td>\n",
       "      <td>120.5300</td>\n",
       "      <td>119.8900</td>\n",
       "      <td>120.1900</td>\n",
       "      <td>119.9175</td>\n",
       "      <td>8153350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>119.84</td>\n",
       "      <td>120.1200</td>\n",
       "      <td>119.3850</td>\n",
       "      <td>119.5600</td>\n",
       "      <td>119.2890</td>\n",
       "      <td>14106447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>120.31</td>\n",
       "      <td>120.7200</td>\n",
       "      <td>120.0700</td>\n",
       "      <td>120.3700</td>\n",
       "      <td>120.0971</td>\n",
       "      <td>8881133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>119.88</td>\n",
       "      <td>120.6200</td>\n",
       "      <td>119.8300</td>\n",
       "      <td>120.3200</td>\n",
       "      <td>120.0472</td>\n",
       "      <td>5776907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>120.91</td>\n",
       "      <td>121.2600</td>\n",
       "      <td>120.7100</td>\n",
       "      <td>121.1100</td>\n",
       "      <td>120.8354</td>\n",
       "      <td>7121480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>120.59</td>\n",
       "      <td>120.7500</td>\n",
       "      <td>120.3200</td>\n",
       "      <td>120.5300</td>\n",
       "      <td>120.2568</td>\n",
       "      <td>6460820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>120.54</td>\n",
       "      <td>120.9400</td>\n",
       "      <td>120.4100</td>\n",
       "      <td>120.4100</td>\n",
       "      <td>120.1370</td>\n",
       "      <td>6435820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>120.53</td>\n",
       "      <td>121.0400</td>\n",
       "      <td>120.3900</td>\n",
       "      <td>121.0200</td>\n",
       "      <td>120.7456</td>\n",
       "      <td>5750177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>120.84</td>\n",
       "      <td>120.9800</td>\n",
       "      <td>120.3300</td>\n",
       "      <td>120.9300</td>\n",
       "      <td>120.6558</td>\n",
       "      <td>10571325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>121.55</td>\n",
       "      <td>122.1800</td>\n",
       "      <td>121.5000</td>\n",
       "      <td>121.9700</td>\n",
       "      <td>121.6935</td>\n",
       "      <td>11843413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>121.48</td>\n",
       "      <td>121.5700</td>\n",
       "      <td>120.8446</td>\n",
       "      <td>120.9600</td>\n",
       "      <td>120.9600</td>\n",
       "      <td>12024576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>120.44</td>\n",
       "      <td>120.5500</td>\n",
       "      <td>120.0200</td>\n",
       "      <td>120.4200</td>\n",
       "      <td>120.4200</td>\n",
       "      <td>8966375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>120.73</td>\n",
       "      <td>121.2300</td>\n",
       "      <td>120.6600</td>\n",
       "      <td>120.9700</td>\n",
       "      <td>120.9700</td>\n",
       "      <td>6983255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>121.36</td>\n",
       "      <td>121.4100</td>\n",
       "      <td>120.7300</td>\n",
       "      <td>121.0300</td>\n",
       "      <td>121.0300</td>\n",
       "      <td>5184018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>121.46</td>\n",
       "      <td>121.9100</td>\n",
       "      <td>121.2300</td>\n",
       "      <td>121.8300</td>\n",
       "      <td>121.8300</td>\n",
       "      <td>8781040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>122.26</td>\n",
       "      <td>122.4700</td>\n",
       "      <td>122.0700</td>\n",
       "      <td>122.3500</td>\n",
       "      <td>122.3500</td>\n",
       "      <td>5885427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>121.86</td>\n",
       "      <td>122.1800</td>\n",
       "      <td>121.7500</td>\n",
       "      <td>121.8700</td>\n",
       "      <td>121.8700</td>\n",
       "      <td>4353004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>121.66</td>\n",
       "      <td>121.7500</td>\n",
       "      <td>121.2000</td>\n",
       "      <td>121.5550</td>\n",
       "      <td>121.5550</td>\n",
       "      <td>7939591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>121.15</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>120.9100</td>\n",
       "      <td>121.1000</td>\n",
       "      <td>121.1000</td>\n",
       "      <td>4757681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>122.14</td>\n",
       "      <td>122.1957</td>\n",
       "      <td>121.6500</td>\n",
       "      <td>121.7633</td>\n",
       "      <td>121.7633</td>\n",
       "      <td>2496779.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open      High       Low     Close  AdjClose      Volume\n",
       "4133  2018-12-26  120.99  121.3900  119.9700  120.0200  119.7479  11700412.0\n",
       "4134  2018-12-27  121.26  121.3800  119.9800  120.0400  119.7679  12146772.0\n",
       "4135  2018-12-28  120.40  121.0500  120.2900  121.0500  120.7756   9879116.0\n",
       "4136  2018-12-31  120.65  121.5600  120.4600  121.5100  121.2345  17408971.0\n",
       "4137  2019-01-02  121.66  122.1600  121.3401  122.1500  121.8731  19841527.0\n",
       "4138  2019-01-03  122.29  123.8600  122.2267  123.5400  123.2599  21187045.0\n",
       "4139  2019-01-04  122.34  122.5600  121.6500  122.1100  121.8332  12970226.0\n",
       "4140  2019-01-07  122.62  122.6500  121.6200  121.7500  121.4740   8498104.0\n",
       "4141  2019-01-08  121.69  121.9400  121.3900  121.4300  121.1547   7737103.0\n",
       "4142  2019-01-09  121.26  121.4300  120.7950  121.2400  120.9651   9349245.0\n",
       "4143  2019-01-10  121.28  121.4100  120.3400  120.4600  120.1869   8222860.0\n",
       "4144  2019-01-11  120.83  121.2700  120.6800  120.9300  120.6558   5786934.0\n",
       "4145  2019-01-14  120.90  121.0100  120.2416  120.4800  120.2069   6730681.0\n",
       "4146  2019-01-15  120.56  120.5700  119.9500  120.0400  119.7679   8997352.0\n",
       "4147  2019-01-16  119.59  120.3900  119.5100  120.1600  119.8876   6048446.0\n",
       "4148  2019-01-17  120.22  120.5300  119.8900  120.1900  119.9175   8153350.0\n",
       "4149  2019-01-18  119.84  120.1200  119.3850  119.5600  119.2890  14106447.0\n",
       "4150  2019-01-22  120.31  120.7200  120.0700  120.3700  120.0971   8881133.0\n",
       "4151  2019-01-23  119.88  120.6200  119.8300  120.3200  120.0472   5776907.0\n",
       "4152  2019-01-24  120.91  121.2600  120.7100  121.1100  120.8354   7121480.0\n",
       "4153  2019-01-25  120.59  120.7500  120.3200  120.5300  120.2568   6460820.0\n",
       "4154  2019-01-28  120.54  120.9400  120.4100  120.4100  120.1370   6435820.0\n",
       "4155  2019-01-29  120.53  121.0400  120.3900  121.0200  120.7456   5750177.0\n",
       "4156  2019-01-30  120.84  120.9800  120.3300  120.9300  120.6558  10571325.0\n",
       "4157  2019-01-31  121.55  122.1800  121.5000  121.9700  121.6935  11843413.0\n",
       "4158  2019-02-01  121.48  121.5700  120.8446  120.9600  120.9600  12024576.0\n",
       "4159  2019-02-04  120.44  120.5500  120.0200  120.4200  120.4200   8966375.0\n",
       "4160  2019-02-05  120.73  121.2300  120.6600  120.9700  120.9700   6983255.0\n",
       "4161  2019-02-06  121.36  121.4100  120.7300  121.0300  121.0300   5184018.0\n",
       "4162  2019-02-07  121.46  121.9100  121.2300  121.8300  121.8300   8781040.0\n",
       "4163  2019-02-08  122.26  122.4700  122.0700  122.3500  122.3500   5885427.0\n",
       "4164  2019-02-11  121.86  122.1800  121.7500  121.8700  121.8700   4353004.0\n",
       "4165  2019-02-12  121.66  121.7500  121.2000  121.5550  121.5550   7939591.0\n",
       "4166  2019-02-13  121.15  121.3900  120.9100  121.1000  121.1000   4757681.0\n",
       "4167  2019-02-14  122.14  122.1957  121.6500  121.7633  121.7633   2496779.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.tail(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim df to 2019-01-09, then add 2019-01-10\n",
    "Don't use set_date_range to update to new date data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-02-15'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeDate = tradeDate.strftime('%Y-%m-%d')\n",
    "tradeDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-020c6b84a88f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Use trade date instead of hard coding date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrimmed_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mraw_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mraw_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtradeDate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrimmed_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Use trade date instead of hard coding date\n",
    "trimmed_df = raw_df.iloc[0:raw_df[raw_df.Date == tradeDate].index[0]]\n",
    "trimmed_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_loc = raw_df.index[raw_df.Date == tradeDate]\n",
    "index = price_loc[0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_open = raw_df.Close[index]\n",
    "new_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2019-01-08\n",
    "new_data_df = trimmed_df.append({'Date' : tradeDate , 'Open' : raw_df.Open[index], 'High' : raw_df.High[index], 'Low' : raw_df.Low[index], 'Close' : raw_df.Close[index], 'AdjClose' : raw_df.AdjClose[index], 'Volume' : raw_df.Volume[index] } , ignore_index=True)\n",
    "new_data_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first row\n",
    "df_start_date = new_data_df.Date[0]\n",
    "df_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last row\n",
    "lastRow = new_data_df.shape[0]\n",
    "df_end_date = new_data_df.Date[lastRow-1]\n",
    "df_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_df = dSet.set_date_range(new_data_df, df_start_date, df_end_date)\n",
    "# Resolve any NA's for now\n",
    "feat_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "#set beLong level\n",
    "beLongThreshold = 0.000\n",
    "feat_df = ct.setTarget(new_data_df, \"Long\", beLongThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding features with new day\n",
    "Should I be generating new features again?\n",
    "How would add just one day's worth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'input_dict.json'\n",
    "file_path = os.path.join(system_directory, file_name)\n",
    "input_dict = load_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = featureGen.generate_features(feat_df, input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_df = transf.normalizer(feat_df, 'Volume', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_vals = [k for k,v in feature_dict.items() if v == 'Drop']\n",
    "to_drop = ['Open','High','Low', 'gainAhead', 'Close', 'Volume', 'AdjClose', 'beLong']\n",
    "for x in to_drop:\n",
    "    col_vals.append(x)\n",
    "model_data = dSet.drop_columns(feat_df, col_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve model\n",
    "best_model_name = system_dict[\"best_model\"]\n",
    "file_title = \"fit-model-\" + best_model_name + \"-IS-\" + system_name + \".sav\"\n",
    "file_name = os.path.join(system_directory, file_title)\n",
    "model = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last row of data\n",
    "lastRow = model_data.shape[0]\n",
    "model_end_date = model_data.index[lastRow-1]\n",
    "print(model_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predict_data = model_data.iloc[lastRow-1]\n",
    "dX = np.zeros_like(predict_data)\n",
    "dX = predict_data.values\n",
    "dX = dX.reshape(1, -1)\n",
    "dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction\n",
    "y_validate = []\n",
    "y_validate = model.predict(dX)\n",
    "y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get shadow trades\n",
    "filename = \"OOS_Equity_daybyday_\" + system_name + \".csv\"\n",
    "path = system_directory+ \"\\\\\" + filename\n",
    "shadow_trades = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_trades.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df.Close[lastRow-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update shadow trades to start\n",
    "- Current date, signal for date, Close for date, gainAhead for previous Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_st_df = shadow_trades.append({'Date' : tradeDate , 'signal' : y_validate[0], 'gainAhead' : 0.000, 'Close' : feat_df.Close[lastRow-1] } , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_st_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_st_df['gainAhead'] = ct.gainAhead(new_st_df.Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_st_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save updated shadow trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(df_to_save)\n",
    "filename = \"OOS_Equity_daybyday_\" + system_name + \".csv\"\n",
    "new_st_df.to_csv(system_directory+ \"\\\\\" + filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load TMS - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"TMS_Part1_daybyday_\" + system_name + \".csv\"\n",
    "path = system_directory+ \"\\\\\" + filename\n",
    "tms1 = pd.read_csv(path)\n",
    "tms1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update TMS-Part 1 data with latest date\n",
    "sst = tms1.append({'Date' : tradeDate , 'signal' : y_validate[0], 'gainAhead' : 0, 'Close' :  feat_df.Close[lastRow-1]} , ignore_index=True)\n",
    "sst.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with gainAhead\n",
    "end = sst.index[-2]\n",
    "sst.iloc[end,sst.columns.get_loc('gainAhead')] = new_st_df.iloc[end,new_st_df.columns.get_loc('gainAhead')]\n",
    "sst.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update TMS-Part 1 with safe-f, CAR25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = sst.shape[0]\n",
    "# sst = sst.set_index(pd.DatetimeIndex(sst['Date']))\n",
    "start = sst.index[0]\n",
    "end = sst.index[-1]\n",
    "\n",
    "iStart = sst.index.get_loc(end)-1\n",
    "iEnd = sst.index.get_loc(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve tms_dict\n",
    "file_name = 'tms_dict.json'\n",
    "file_path = os.path.join(system_directory, file_name)\n",
    "tms_dict = load_json(file_path)\n",
    "\n",
    "forecastHorizon = tms_dict[\"forecastHorizon\"]\n",
    "initialEquity = tms_dict[\"initialEquity\"]\n",
    "ddTolerance = tms_dict[\"ddTolerance\"]\n",
    "tailRiskPct = tms_dict[\"tailRiskPct\"]\n",
    "windowLength = tms_dict[\"windowLength\"]\n",
    "nCurves = tms_dict[\"nCurves\"]\n",
    "updateInterval = tms_dict[\"updateInterval\"]\n",
    "\n",
    "years_in_forecast = forecastHorizon / 252.0\n",
    "\n",
    "printDetails = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate safe-f, CAR25\n",
    "for i in range(iStart, iEnd+1, updateInterval):\n",
    "    if printDetails: \n",
    "        print (\"\\nDate: \", dt.datetime.strftime(sst.index[i], '%Y-%m-%d'))\n",
    "        print (\"beLong: \", sst.signal[i])\n",
    "        print (\"gain Ahead: {0:.4f}\".format(sst.gainAhead[i]))\n",
    "\n",
    "#  Initialize variables\n",
    "    curves = np.zeros(nCurves)\n",
    "    numberDraws = np.zeros(nCurves)\n",
    "    TWR = np.zeros(nCurves)\n",
    "    maxDD = np.zeros(nCurves)\n",
    "    \n",
    "    fraction = 1.00\n",
    "    dd95 = 2 * ddTolerance\n",
    "    \n",
    "    while (abs(dd95-ddTolerance)>0.03):\n",
    "        #  Generate nCurve equity curves\n",
    "        if printDetails: \n",
    "            print  (\"    Fraction {0:.2f}\".format(fraction))\n",
    "#    \n",
    "        for nc in range(nCurves):\n",
    "            #print (\"working on curve \", nc)\n",
    "            equity = initialEquity\n",
    "            maxEquity = equity\n",
    "            drawdown = 0\n",
    "            maxDrawdown = 0\n",
    "            horizonSoFar = 0\n",
    "            nd = 0\n",
    "            while (horizonSoFar < forecastHorizon):\n",
    "                j = np.random.randint(0,windowLength)\n",
    "        #        print j\n",
    "                nd = nd + 1\n",
    "                weightJ = 1.00 - j/windowLength\n",
    "        #        print weightJ\n",
    "                horizonSoFar = horizonSoFar + weightJ\n",
    "                signalJ = sst.signal[i-j]\n",
    "                if signalJ > 0:\n",
    "                    tradeJ = sst.gainAhead[i-j] * weightJ\n",
    "                else:\n",
    "                    tradeJ = 0.0\n",
    "                thisTrade = fraction * tradeJ * equity    \n",
    "                equity = equity + thisTrade\n",
    "                maxEquity = max(equity,maxEquity)\n",
    "                drawdown = (maxEquity-equity)/maxEquity\n",
    "                maxDrawdown = max(drawdown,maxDrawdown)\n",
    "    #        print \"equity, maxDD, ndraws:\", equity, maxDrawdown, nd        \n",
    "            TWR[nc] = equity\n",
    "            maxDD[nc] = maxDrawdown\n",
    "            numberDraws[nc] = nd\n",
    "    \n",
    "        #  Find the drawdown at the tailLimit-th percentile        \n",
    "        dd95 = stats.scoreatpercentile(maxDD,tailRiskPct)\n",
    "        if printDetails: \n",
    "            print ('  DD {0}: {1:.3f} '.format(tailRiskPct, dd95))\n",
    "        fraction = fraction * ddTolerance / dd95\n",
    "        TWR25 = stats.scoreatpercentile(TWR,25)        \n",
    "        CAR25 = 100*(((TWR25/initialEquity) ** (1.0/years_in_forecast))-1.0)\n",
    "    if printDetails: \n",
    "        print ('Fraction: {0:.2f}'.format(fraction))\n",
    "        print ('CAR25: {0:.2f}'.format(CAR25))\n",
    "    sst.iloc[i,sst.columns.get_loc('safef')] = fraction\n",
    "    sst.iloc[i,sst.columns.get_loc('CAR25')] = CAR25\n",
    "    #sst.loc[i,'CAR25'] = CAR25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save updated shadow trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_to_save = sst.copy()\n",
    "#df_to_save.reset_index(level=df_to_save.index.names, inplace=True)\n",
    "filename = \"TMS_Part1_daybyday_\" + system_name + \".csv\"\n",
    "df_to_save.to_csv(system_directory+ \"\\\\\" + filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now go to TMS Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"TMS_Part2_daybyday_\" + system_name + \".csv\"\n",
    "path = system_directory+ \"\\\\\" + filename\n",
    "tms2 = pd.read_csv(path)\n",
    "tms2.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append last day  form TMS Part 1 to TMS Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tms21 = tms2.copy()\n",
    "sst1 = sst.copy()\n",
    "#sst1.reset_index(level=sst1.index.names, inplace=True)\n",
    "tms21.loc[sst1.index[-1]] = sst1.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms21.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = tms21.shape[0]\n",
    "start = tms21.index[0]\n",
    "end = tms21.index[-1]\n",
    "\n",
    "iStart = tms21.index.get_loc(end)-1\n",
    "iEnd = tms21.index.get_loc(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update gainAhead\n",
    "tms21.iloc[iStart,tms21.columns.get_loc('gainAhead')] = sst1.iloc[iStart,sst1.columns.get_loc('gainAhead')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms21.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update trade_decision with current date decision\n",
    "if y_validate[0] == 1:\n",
    "    tms21.iloc[iEnd,tms21.columns.get_loc('trade_decision')] = 'Long'\n",
    "else:\n",
    "    tms21.iloc[iEnd,tms21.columns.get_loc('trade_decision')] = 'Flat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms21.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(iStart, iEnd):\n",
    "    if (tms21.trade_decision[i] == 'Long'):\n",
    "        tms21.iloc[i,tms21.columns.get_loc('trade')] = tms21.iloc[i-1,tms21.columns.get_loc('fract')] * tms21.iloc[i-1,tms21.columns.get_loc('equity')] * tms21.iloc[i,tms21.columns.get_loc('gainAhead')]\n",
    "    elif (tms21.signal[i] > 0):\n",
    "        tms21.iloc[i,tms21.columns.get_loc('trade')] = tms21.iloc[i-1,tms21.columns.get_loc('fract')] * tms21.iloc[i-1,tms21.columns.get_loc('equity')] * tms21.iloc[i,tms21.columns.get_loc('gainAhead')]\n",
    "    else:\n",
    "        tms21.iloc[i,tms21.columns.get_loc('trade')] = 0.0\n",
    "        \n",
    "    tms21.iloc[i,tms21.columns.get_loc('fract')] = tms21.iloc[i,tms21.columns.get_loc('safef')]\n",
    "    \n",
    "    tms21.iloc[i,tms21.columns.get_loc('equity')] = tms21.iloc[i-1,tms21.columns.get_loc('equity')] + tms21.iloc[i,tms21.columns.get_loc('trade')]\n",
    "    tms21.iloc[i,tms21.columns.get_loc('maxEquity')] = max(tms21.iloc[i,tms21.columns.get_loc('equity')],tms21.iloc[i-1,tms21.columns.get_loc('maxEquity')])\n",
    "    tms21.iloc[i,tms21.columns.get_loc('drawdown')] = (tms21.iloc[i,tms21.columns.get_loc('maxEquity')] - tms21.iloc[i,tms21.columns.get_loc('equity')]) / tms21.iloc[i,tms21.columns.get_loc('maxEquity')]\n",
    "    tms21.iloc[i,tms21.columns.get_loc('maxDD')] =  max(tms21.iloc[i,tms21.columns.get_loc('drawdown')],tms21.iloc[i-1,tms21.columns.get_loc('maxDD')])\n",
    "    tms21.iloc[i,tms21.columns.get_loc('fract')] = tms21.iloc[i,tms21.columns.get_loc('safef')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms21.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save updated TMS Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_to_save = tms21.copy()\n",
    "#df_to_save.reset_index(level=df_to_save.index.names, inplace=True)\n",
    "filename = \"TMS_Part2_daybyday_\" + system_name + \".csv\"\n",
    "df_to_save.to_csv(system_directory+ \"\\\\\" + filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_dict['pivot_date']=tradeDate\n",
    "system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_json('system_dict.json', system_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of day completed\n",
    "Trade decision: Long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plot the equity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot equity and drawdown curves\n",
    "plot_tms = tms21.copy()\n",
    "plot_tms = plot_tms.set_index(pd.DatetimeIndex(plot_tms['Date']))\n",
    "plot_tms=plot_tms.drop('Date', axis=1)\n",
    "plotTitle = \"Equity curve for  \" + issue + \", \" + str(start) + \" to \" + str(end)\n",
    "plotIt.plot_v1(plot_tms['equity'][:-2], plotTitle)\n",
    "plotTitle = \"Drawdown for  \" + issue + \", \" + str(start) + \" to \" + str(end)\n",
    "plotIt.plot_v1(plot_tms['drawdown'][:-2], plotTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the equity stream\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "fig.suptitle('CAR25 and issue price for' + issue)\n",
    "ax1 = fig.add_subplot(111)\n",
    "#ax1.plot(sst1.safef, color='green',label='safe-f')\n",
    "ax1.plot(plot_tms['CAR25'][:-2], color='blue',label='CAR25')\n",
    "#ax1.plot(valData.equityValBeLongSignals, color='purple',label='ValBeLong')\n",
    "\n",
    "ax1.legend(loc='upper left', frameon=True, fontsize=8)\n",
    "ax1.label_outer()\n",
    "ax1.tick_params(axis='x',which='major',bottom=True)\n",
    "ax1.minorticks_on()\n",
    "ax1.grid(True, which='major', color='k', linestyle='-', alpha=0.6)\n",
    "ax1.grid(True, which='minor', color='r', linestyle='-', alpha=0.2)\n",
    "\n",
    "#sst1['Pri']=valData.Pri\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(plot_tms['Close'][:-2], color='black',alpha=0.6,label='CLOSE',linestyle='--')\n",
    "ax2.legend(loc='center left', frameon=True, fontsize=8)\n",
    "ax2.label_outer()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
