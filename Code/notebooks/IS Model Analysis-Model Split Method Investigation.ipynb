{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Model Performance and Walf Foward Validation Techniques\n",
    "Investigate various methods for model performance and WF validation\n",
    "1. Currently using Stratified Shuffle Split based on QTS book\n",
    "    - Should I continue to use...probably not\n",
    "2. Have read in RobotWealth and Hyndman that time series WF validation should use time series type split, also called \"rolling origin\" forecast\n",
    "    - How does this affect CM calculations?\n",
    "    - Should I use repeated CV?\n",
    "    - Should I use custom created rolling original that doesn't use who series like time series split?\n",
    "        - Use rolling series of data?\n",
    "\n",
    "For time-dependent data, we can employ walk-forward analysis or rolling forecast origin techniques. This comes in various flavors (see the below illustration).  We first divide up the data set into, say, ten periods. We first fit a trading algorithm on the first period in the data set, then see how it performs on the “out-of-sample” second period. Then we repeat for the second and third periods, third and fourth periods, and so on until we’ve run to the end of the data set. The out-of-sample data sets are then used for evaluating the potential performance of the trading system in question. If we like, we may be keeping a final data set, perhaps the most recent data set, for final evaluation of whatever trading system passes this initial test.\n",
    "![Image](split_time-1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Code.lib.plot_utils import PlotUtility\n",
    "from Code.lib.time_utils import TimeUtility\n",
    "from Code.lib.model_utils import ModelUtility\n",
    "from Code.lib.retrieve_data import DataRetrieve, ComputeTarget\n",
    "from Code.lib.config import current_feature, feature_dict\n",
    "from Code.models import models_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved data series for TLT\n"
     ]
    }
   ],
   "source": [
    "timeUtil = TimeUtility()\n",
    "ct = ComputeTarget()\n",
    "dSet = DataRetrieve()\n",
    "modelUtil = ModelUtility()\n",
    "    \n",
    "issue = \"TLT\"\n",
    "# Set IS-OOS parameters\n",
    "pivotDate = datetime.date(2019, 1, 3)\n",
    "is_oos_ratio = 2\n",
    "oos_months = 6\n",
    "segments = 2\n",
    "\n",
    "df = dSet.read_issue_data(issue)\n",
    "dataLoadStartDate = df.Date[0]\n",
    "lastRow = df.shape[0]\n",
    "dataLoadEndDate = df.Date[lastRow-1]\n",
    "dataSet = dSet.set_date_range(df, dataLoadStartDate,dataLoadEndDate)\n",
    "# Resolve any NA's for now\n",
    "dataSet.fillna(method='ffill', inplace=True)\n",
    "#set beLong level\n",
    "beLongThreshold = 0.000\n",
    "dataSet = ct.setTarget(dataSet, \"Long\", beLongThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set date range for analysis using the typical IS-OOS ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Segments:  2\n",
      "                IS OOS Ratio:  2\n",
      "                  OOS months:  6\n",
      "                   IS Months:  12\n",
      "              Months to load:  30\n",
      "              Data Load Date:  2016-12-03\n",
      "              IS Start  Date:  2017-01-03\n",
      "              OOS Start Date:  2018-01-03\n",
      "                  Pivot Date:  2019-01-03\n",
      "Issue: TLT\n",
      "Start date: 2017-01-03  End date: 2018-01-03\n"
     ]
    }
   ],
   "source": [
    "# set date splits\n",
    "isOosDates = timeUtil.is_oos_data_split(issue, pivotDate, is_oos_ratio, oos_months, segments)\n",
    "dataLoadStartDate = isOosDates[0]\n",
    "is_start_date = isOosDates[1]\n",
    "oos_start_date = isOosDates[2]\n",
    "is_months = isOosDates[3]\n",
    "is_end_date = isOosDates[4]\n",
    "oos_end_date = isOosDates[5]\n",
    "\n",
    "modelStartDate = is_start_date\n",
    "modelEndDate = modelStartDate + relativedelta(months=is_months)\n",
    "print(\"Issue: \" + issue)\n",
    "print(\"Start date: \" + str(modelStartDate) + \"  End date: \" + str(modelEndDate))\n",
    "mmData = dataSet[modelStartDate:modelEndDate].copy()\n",
    "model_results = []\n",
    "predictor_vars = \"Temp holding spot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep data sets for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dX, dy = modelUtil.prepare_for_classification(mmData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate TimeSeriesSplit parameters\n",
    "#### Fixed Window: FALSE, Overlapping: TRUE, Number of splits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28] TEST: [29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56] TEST: [57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84] TEST: [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112] TEST: [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140] TEST: [141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n",
      " 159 160 161 162 163 164 165 166 167 168]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168] TEST: [169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196] TEST: [197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218 219 220 221 222 223 224]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224] TEST: [225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=8)\n",
    "for train_index, test_index in tscv.split(dX,dy):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: FALSE, Overlapping: TRUE, Number of splits = 8, Max Train size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63] TEST: [ 64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126]\n",
      "TRAIN: [103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126] TEST: [127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189]\n",
      "TRAIN: [166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189] TEST: [190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
      " 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243\n",
      " 244 245 246 247 248 249 250 251 252]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3, max_train_size=24)\n",
    "for train_index, test_index in tscv.split(dX,dy):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigation of the Improved TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TimeSeriesSplitImproved(TimeSeriesSplit):\n",
    "    \"\"\"Time Series cross-validator\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals, in train/test sets.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide `.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of splits. Must be at least 1.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.model_selection import TimeSeriesSplit\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4])\n",
    "    >>> tscv = TimeSeriesSplit(n_splits=3)\n",
    "    >>> print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    TimeSeriesSplit(n_splits=3)\n",
    "    >>> for train_index, test_index in tscv.split(X):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [0 1 2] TEST: [3]\n",
    "    >>> for train_index, test_index in tscv.split(X, fixed_length=True):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [1] TEST: [2]\n",
    "    TRAIN: [2] TEST: [3]\n",
    "    >>> for train_index, test_index in tscv.split(X, fixed_length=True,\n",
    "    ...     train_splits=2):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [1 2] TEST: [3]\n",
    " \n",
    "    Notes\n",
    "    -----\n",
    "    When ``fixed_length`` is ``False``, the training set has size\n",
    "    ``i * train_splits * n_samples // (n_splits + 1) + n_samples %\n",
    "    (n_splits + 1)`` in the ``i``th split, with a test set of size\n",
    "    ``n_samples//(n_splits + 1) * test_splits``, where ``n_samples``\n",
    "    is the number of samples. If fixed_length is True, replace ``i``\n",
    "    in the above formulation with 1, and ignore ``n_samples %\n",
    "    (n_splits + 1)`` except for the first training set. The number\n",
    "    of test sets is ``n_splits + 2 - train_splits - test_splits``.\n",
    "    \"\"\"\n",
    " \n",
    "    def split(self, X, y=None, groups=None, fixed_length=False, train_splits=1, test_splits=1):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like, with shape (n_samples,), optional\n",
    "            Always ignored, exists for compatibility.\n",
    "        fixed_length : bool, hether training sets should always have\n",
    "            common length\n",
    "        train_splits : positive int, for the minimum number of\n",
    "            splits to include in training sets\n",
    "        test_splits : positive int, for the number of splits to\n",
    "            include in the test set\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        train_splits, test_splits = int(train_splits), int(test_splits)\n",
    "        if n_folds > n_samples:\n",
    "            raise ValueError((\"Cannot have number of folds ={0} greater than the number of samples: {1}.\").format(n_folds,n_samples))\n",
    "        if (n_folds - train_splits - test_splits) < 0 and test_splits > 0:\n",
    "            raise ValueError(\"Both train_splits and test_splits must be positive integers.\")\n",
    "        indices = np.arange(n_samples)\n",
    "        split_size = (n_samples // n_folds)\n",
    "        test_size = split_size * test_splits\n",
    "        train_size = split_size * train_splits\n",
    "        test_starts = range(train_size + n_samples % n_folds, n_samples - (test_size - split_size), split_size)\n",
    "        if fixed_length:\n",
    "            for i, test_start in zip(range(len(test_starts)), test_starts):\n",
    "                rem = 0\n",
    "                if i == 0:\n",
    "                    rem = n_samples % n_folds\n",
    "                yield (indices[(test_start - train_size - rem):test_start],\n",
    "                       indices[test_start:test_start + test_size])\n",
    "        else:\n",
    "            for test_start in test_starts:\n",
    "                yield (indices[:test_start],\n",
    "                    indices[test_start:test_start + test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: TRUE, Number of splits = 10, Train splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112] TEST: [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140]\n",
      "TRAIN: [ 29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46\n",
      "  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
      " 137 138 139 140] TEST: [141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n",
      " 159 160 161 162 163 164 165 166 167 168]\n",
      "TRAIN: [ 57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
      " 165 166 167 168] TEST: [169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196]\n",
      "TRAIN: [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n",
      " 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174\n",
      " 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192\n",
      " 193 194 195 196] TEST: [197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218 219 220 221 222 223 224]\n",
      "TRAIN: [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202\n",
      " 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220\n",
      " 221 222 223 224] TEST: [225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=8)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True, train_splits=4):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: TRUE, Number of splits = 25, Train splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] TEST: [ 73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108]\n",
      "TRAIN: [ 37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108] TEST: [109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144]\n",
      "TRAIN: [ 73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144] TEST: [145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180]\n",
      "TRAIN: [109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180] TEST: [181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216]\n",
      "TRAIN: [145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216] TEST: [217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=6)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True, train_splits=2):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: FALSE, Number of splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42] TEST: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\n",
      " 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84]\n",
      "TRAIN: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\n",
      " 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84] TEST: [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126]\n",
      "TRAIN: [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126] TEST: [127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168]\n",
      "TRAIN: [127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168] TEST: [169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210]\n",
      "TRAIN: [169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210] TEST: [211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246\n",
      " 247 248 249 250 251 252]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=5)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: FALSE, Number of splits = 10, Test splits = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22] TEST: [23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68]\n",
      "TRAIN: [23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] TEST: [46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70\n",
      " 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "TRAIN: [46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68] TEST: [ 69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114]\n",
      "TRAIN: [69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91] TEST: [ 92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137]\n",
      "TRAIN: [ 92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114] TEST: [115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151 152 153 154 155 156 157 158 159 160]\n",
      "TRAIN: [115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137] TEST: [138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173\n",
      " 174 175 176 177 178 179 180 181 182 183]\n",
      "TRAIN: [138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160] TEST: [161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206]\n",
      "TRAIN: [161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183] TEST: [184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
      " 220 221 222 223 224 225 226 227 228 229]\n",
      "TRAIN: [184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206] TEST: [207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=10)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True, train_splits=1,test_splits=2):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
