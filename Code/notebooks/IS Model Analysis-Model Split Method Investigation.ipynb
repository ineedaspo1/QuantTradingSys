{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Model Performance and Walf Foward Validation Techniques\n",
    "Investigate various methods for model performance and WF validation\n",
    "1. Currently using Stratified Shuffle Split based on QTS book\n",
    "    - Should I continue to use...probably not\n",
    "2. Have read in RobotWealth and Hyndman that time series WF validation should use time series type split, also called \"rolling origin\" forecast\n",
    "    - How does this affect CM calculations?\n",
    "    - Should I use repeated CV?\n",
    "    - Should I use custom created rolling original that doesn't use who series like time series split?\n",
    "        - Use rolling series of data?\n",
    "\n",
    "For time-dependent data, we can employ walk-forward analysis or rolling forecast origin techniques. This comes in various flavors (see the below illustration).  We first divide up the data set into, say, ten periods. We first fit a trading algorithm on the first period in the data set, then see how it performs on the “out-of-sample” second period. Then we repeat for the second and third periods, third and fourth periods, and so on until we’ve run to the end of the data set. The out-of-sample data sets are then used for evaluating the potential performance of the trading system in question. If we like, we may be keeping a final data set, perhaps the most recent data set, for final evaluation of whatever trading system passes this initial test.\n",
    "![Image](split_time-1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Code.lib.plot_utils import PlotUtility\n",
    "from Code.lib.time_utils import TimeUtility\n",
    "from Code.lib.model_utils import ModelUtility\n",
    "from Code.lib.retrieve_data import DataRetrieve, ComputeTarget\n",
    "from Code.lib.config import current_feature, feature_dict\n",
    "from Code.models import models_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved data series for TLT\n"
     ]
    }
   ],
   "source": [
    "timeUtil = TimeUtility()\n",
    "ct = ComputeTarget()\n",
    "dSet = DataRetrieve()\n",
    "modelUtil = ModelUtility()\n",
    "    \n",
    "issue = \"TLT\"\n",
    "# Set IS-OOS parameters\n",
    "pivotDate = datetime.date(2019, 1, 3)\n",
    "is_oos_ratio = 2\n",
    "oos_months = 4\n",
    "segments = 4\n",
    "\n",
    "df = dSet.read_issue_data(issue)\n",
    "dataLoadStartDate = df.Date[0]\n",
    "lastRow = df.shape[0]\n",
    "dataLoadEndDate = df.Date[lastRow-1]\n",
    "dataSet = dSet.set_date_range(df, dataLoadStartDate,dataLoadEndDate)\n",
    "# Resolve any NA's for now\n",
    "dataSet.fillna(method='ffill', inplace=True)\n",
    "#set beLong level\n",
    "beLongThreshold = 0.000\n",
    "dataSet = ct.setTarget(dataSet, \"Long\", beLongThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set date range for analysis using the typical IS-OOS ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Segments:  4\n",
      "                IS OOS Ratio:  2\n",
      "                  OOS months:  4\n",
      "                   IS Months:  8\n",
      "              Months to load:  36\n",
      "              Data Load Date:  2016-12-03\n",
      "              IS Start  Date:  2017-01-03\n",
      "              OOS Start Date:  2017-09-03\n",
      "                  Pivot Date:  2019-01-03\n",
      "Issue: TLT\n",
      "Start date: 2017-01-03  End date: 2017-09-03\n"
     ]
    }
   ],
   "source": [
    "# set date splits\n",
    "isOosDates = timeUtil.is_oos_data_split(issue, pivotDate, is_oos_ratio, oos_months, segments)\n",
    "dataLoadStartDate = isOosDates[0]\n",
    "is_start_date = isOosDates[1]\n",
    "oos_start_date = isOosDates[2]\n",
    "is_months = isOosDates[3]\n",
    "is_end_date = isOosDates[4]\n",
    "oos_end_date = isOosDates[5]\n",
    "\n",
    "modelStartDate = is_start_date\n",
    "modelEndDate = modelStartDate + relativedelta(months=is_months)\n",
    "print(\"Issue: \" + issue)\n",
    "print(\"Start date: \" + str(modelStartDate) + \"  End date: \" + str(modelEndDate))\n",
    "mmData = dataSet[modelStartDate:modelEndDate].copy()\n",
    "model_results = []\n",
    "predictor_vars = \"Temp holding spot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep data sets for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dX, dy = modelUtil.prepare_for_classification(mmData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate TimeSeriesSplit parameters\n",
    "#### Fixed Window: FALSE, Overlapping: TRUE, Number of splits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] TEST: [25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42] TEST: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60] TEST: [61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78] TEST: [79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96] TEST: [ 97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114] TEST: [115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132] TEST: [133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150] TEST: [151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=8)\n",
    "for train_index, test_index in tscv.split(dX,dy):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: FALSE, Overlapping: TRUE, Number of splits = 8, Max Train size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42] TEST: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\n",
      " 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84]\n",
      "TRAIN: [61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84] TEST: [ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126]\n",
      "TRAIN: [103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126] TEST: [127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3, max_train_size=24)\n",
    "for train_index, test_index in tscv.split(dX,dy):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigation of the Improved TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TimeSeriesSplitImproved(TimeSeriesSplit):\n",
    "    \"\"\"Time Series cross-validator\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals, in train/test sets.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide `.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of splits. Must be at least 1.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.model_selection import TimeSeriesSplit\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4])\n",
    "    >>> tscv = TimeSeriesSplit(n_splits=3)\n",
    "    >>> print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    TimeSeriesSplit(n_splits=3)\n",
    "    >>> for train_index, test_index in tscv.split(X):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [0 1 2] TEST: [3]\n",
    "    >>> for train_index, test_index in tscv.split(X, fixed_length=True):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [1] TEST: [2]\n",
    "    TRAIN: [2] TEST: [3]\n",
    "    >>> for train_index, test_index in tscv.split(X, fixed_length=True,\n",
    "    ...     train_splits=2):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [1 2] TEST: [3]\n",
    " \n",
    "    Notes\n",
    "    -----\n",
    "    When ``fixed_length`` is ``False``, the training set has size\n",
    "    ``i * train_splits * n_samples // (n_splits + 1) + n_samples %\n",
    "    (n_splits + 1)`` in the ``i``th split, with a test set of size\n",
    "    ``n_samples//(n_splits + 1) * test_splits``, where ``n_samples``\n",
    "    is the number of samples. If fixed_length is True, replace ``i``\n",
    "    in the above formulation with 1, and ignore ``n_samples %\n",
    "    (n_splits + 1)`` except for the first training set. The number\n",
    "    of test sets is ``n_splits + 2 - train_splits - test_splits``.\n",
    "    \"\"\"\n",
    " \n",
    "    def split(self, X, y=None, groups=None, fixed_length=False, train_splits=1, test_splits=1):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like, with shape (n_samples,), optional\n",
    "            Always ignored, exists for compatibility.\n",
    "        fixed_length : bool, hether training sets should always have\n",
    "            common length\n",
    "        train_splits : positive int, for the minimum number of\n",
    "            splits to include in training sets\n",
    "        test_splits : positive int, for the number of splits to\n",
    "            include in the test set\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        train_splits, test_splits = int(train_splits), int(test_splits)\n",
    "        if n_folds > n_samples:\n",
    "            raise ValueError((\"Cannot have number of folds ={0} greater than the number of samples: {1}.\").format(n_folds,n_samples))\n",
    "        if (n_folds - train_splits - test_splits) < 0 and test_splits > 0:\n",
    "            raise ValueError(\"Both train_splits and test_splits must be positive integers.\")\n",
    "        indices = np.arange(n_samples)\n",
    "        split_size = (n_samples // n_folds)\n",
    "        test_size = split_size * test_splits\n",
    "        train_size = split_size * train_splits\n",
    "        test_starts = range(train_size + n_samples % n_folds, n_samples - (test_size - split_size), split_size)\n",
    "        if fixed_length:\n",
    "            for i, test_start in zip(range(len(test_starts)), test_starts):\n",
    "                rem = 0\n",
    "                if i == 0:\n",
    "                    rem = n_samples % n_folds\n",
    "                yield (indices[(test_start - train_size - rem):test_start],\n",
    "                       indices[test_start:test_start + test_size])\n",
    "        else:\n",
    "            for test_start in test_starts:\n",
    "                yield (indices[:test_start],\n",
    "                    indices[test_start:test_start + test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: TRUE, Number of splits = 10, Train splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78] TEST: [79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96]\n",
      "TRAIN: [25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96] TEST: [ 97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114]\n",
      "TRAIN: [ 43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114] TEST: [115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "TRAIN: [ 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132] TEST: [133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150]\n",
      "TRAIN: [ 79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150] TEST: [151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=8)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True, train_splits=4):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: TRUE, Number of splits = 25, Train splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38] TEST: [39 40 41 42]\n",
      "TRAIN: [27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42] TEST: [43 44 45 46]\n",
      "TRAIN: [31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46] TEST: [47 48 49 50]\n",
      "TRAIN: [35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50] TEST: [51 52 53 54]\n",
      "TRAIN: [39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54] TEST: [55 56 57 58]\n",
      "TRAIN: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58] TEST: [59 60 61 62]\n",
      "TRAIN: [47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62] TEST: [63 64 65 66]\n",
      "TRAIN: [51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66] TEST: [67 68 69 70]\n",
      "TRAIN: [55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70] TEST: [71 72 73 74]\n",
      "TRAIN: [59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74] TEST: [75 76 77 78]\n",
      "TRAIN: [63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78] TEST: [79 80 81 82]\n",
      "TRAIN: [67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82] TEST: [83 84 85 86]\n",
      "TRAIN: [71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86] TEST: [87 88 89 90]\n",
      "TRAIN: [75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90] TEST: [91 92 93 94]\n",
      "TRAIN: [79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] TEST: [95 96 97 98]\n",
      "TRAIN: [83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98] TEST: [ 99 100 101 102]\n",
      "TRAIN: [ 87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102] TEST: [103 104 105 106]\n",
      "TRAIN: [ 91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106] TEST: [107 108 109 110]\n",
      "TRAIN: [ 95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110] TEST: [111 112 113 114]\n",
      "TRAIN: [ 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114] TEST: [115 116 117 118]\n",
      "TRAIN: [103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118] TEST: [119 120 121 122]\n",
      "TRAIN: [107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122] TEST: [123 124 125 126]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=25)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True, train_splits=4):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: FALSE, Number of splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] TEST: [17 18 19 20 21 22 23 24 25 26 27]\n",
      "TRAIN: [17 18 19 20 21 22 23 24 25 26 27] TEST: [28 29 30 31 32 33 34 35 36 37 38]\n",
      "TRAIN: [28 29 30 31 32 33 34 35 36 37 38] TEST: [39 40 41 42 43 44 45 46 47 48 49]\n",
      "TRAIN: [39 40 41 42 43 44 45 46 47 48 49] TEST: [50 51 52 53 54 55 56 57 58 59 60]\n",
      "TRAIN: [50 51 52 53 54 55 56 57 58 59 60] TEST: [61 62 63 64 65 66 67 68 69 70 71]\n",
      "TRAIN: [61 62 63 64 65 66 67 68 69 70 71] TEST: [72 73 74 75 76 77 78 79 80 81 82]\n",
      "TRAIN: [72 73 74 75 76 77 78 79 80 81 82] TEST: [83 84 85 86 87 88 89 90 91 92 93]\n",
      "TRAIN: [83 84 85 86 87 88 89 90 91 92 93] TEST: [ 94  95  96  97  98  99 100 101 102 103 104]\n",
      "TRAIN: [ 94  95  96  97  98  99 100 101 102 103 104] TEST: [105 106 107 108 109 110 111 112 113 114 115]\n",
      "TRAIN: [105 106 107 108 109 110 111 112 113 114 115] TEST: [116 117 118 119 120 121 122 123 124 125 126]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=10)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Window: TRUE, Overlapping: FALSE, Number of splits = 10, Test splits = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] TEST: [17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38]\n",
      "TRAIN: [17 18 19 20 21 22 23 24 25 26 27] TEST: [28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]\n",
      "TRAIN: [28 29 30 31 32 33 34 35 36 37 38] TEST: [39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60]\n",
      "TRAIN: [39 40 41 42 43 44 45 46 47 48 49] TEST: [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "TRAIN: [50 51 52 53 54 55 56 57 58 59 60] TEST: [61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82]\n",
      "TRAIN: [61 62 63 64 65 66 67 68 69 70 71] TEST: [72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93]\n",
      "TRAIN: [72 73 74 75 76 77 78 79 80 81 82] TEST: [ 83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104]\n",
      "TRAIN: [83 84 85 86 87 88 89 90 91 92 93] TEST: [ 94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115]\n",
      "TRAIN: [ 94  95  96  97  98  99 100 101 102 103 104] TEST: [105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126]\n"
     ]
    }
   ],
   "source": [
    "tscvi = TimeSeriesSplitImproved(n_splits=10)\n",
    "for train_index, test_index in tscvi.split(dX, fixed_length=True, train_splits=1,test_splits=2):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = dX[train_index], dX[test_index]\n",
    "    y_train, y_test = dy[train_index], dy[test_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
